{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a1c7cf3-d1e8-407d-912b-2d846075e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e3df9c-3c7c-46b0-a908-22fc08721575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1094103d-b300-4217-975e-8527e56d254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab9846e-ffba-418d-9e73-d1fa669879ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdda79d1-a3d0-40cf-afba-accefcce3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7808eb-d01a-4e04-b4f3-6424affb9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7761def6-9753-41e5-a5ee-fe73e6e4a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970f52e1-ee2e-4abc-8fff-c3169b22f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.315897  [   64/60000]\n",
      "loss: 2.299589  [ 6464/60000]\n",
      "loss: 2.286253  [12864/60000]\n",
      "loss: 2.270481  [19264/60000]\n",
      "loss: 2.257290  [25664/60000]\n",
      "loss: 2.231647  [32064/60000]\n",
      "loss: 2.237676  [38464/60000]\n",
      "loss: 2.207334  [44864/60000]\n",
      "loss: 2.202379  [51264/60000]\n",
      "loss: 2.168335  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 2.163441 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.179944  [   64/60000]\n",
      "loss: 2.165737  [ 6464/60000]\n",
      "loss: 2.118680  [12864/60000]\n",
      "loss: 2.127170  [19264/60000]\n",
      "loss: 2.079838  [25664/60000]\n",
      "loss: 2.025388  [32064/60000]\n",
      "loss: 2.050119  [38464/60000]\n",
      "loss: 1.975375  [44864/60000]\n",
      "loss: 1.977877  [51264/60000]\n",
      "loss: 1.907364  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 1.904318 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.934278  [   64/60000]\n",
      "loss: 1.904529  [ 6464/60000]\n",
      "loss: 1.795844  [12864/60000]\n",
      "loss: 1.835558  [19264/60000]\n",
      "loss: 1.727200  [25664/60000]\n",
      "loss: 1.675634  [32064/60000]\n",
      "loss: 1.691488  [38464/60000]\n",
      "loss: 1.586412  [44864/60000]\n",
      "loss: 1.606488  [51264/60000]\n",
      "loss: 1.503172  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.523347 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.583657  [   64/60000]\n",
      "loss: 1.552316  [ 6464/60000]\n",
      "loss: 1.401960  [12864/60000]\n",
      "loss: 1.478472  [19264/60000]\n",
      "loss: 1.358179  [25664/60000]\n",
      "loss: 1.351993  [32064/60000]\n",
      "loss: 1.361500  [38464/60000]\n",
      "loss: 1.277347  [44864/60000]\n",
      "loss: 1.313171  [51264/60000]\n",
      "loss: 1.218392  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.246879 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.322131  [   64/60000]\n",
      "loss: 1.306827  [ 6464/60000]\n",
      "loss: 1.136176  [12864/60000]\n",
      "loss: 1.247290  [19264/60000]\n",
      "loss: 1.125507  [25664/60000]\n",
      "loss: 1.150330  [32064/60000]\n",
      "loss: 1.166637  [38464/60000]\n",
      "loss: 1.092781  [44864/60000]\n",
      "loss: 1.134987  [51264/60000]\n",
      "loss: 1.059929  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.080980 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b36edf9-4f09-4ef4-8002-e6378d54c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c42ccf2-3675-4ba1-8e30-63744e89e299",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (701043924.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.load_state_dict(torch.load(\"model.pth\"))sd\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50eef13f-fe8c-45da-bd15-00787f16aa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Coat\", Actual: \"Coat\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[10][0], test_data[10][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c99030-035f-4204-bd1c-68bc43a6c938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1232, -1.4327,  2.3718, -0.6713,  2.4326, -1.2177,  1.7662, -2.1951,\n",
       "         0.6749, -1.4333], device='mps:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a86f830-9efe-47c0-b1ee-6ba753a60ef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c1a440-714f-45af-82b8-6697711456fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c33e88f-01af-4c85-9554-13e0a1e4cbf7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0179,  0.0346,  0.0131,  ...,  0.0124, -0.0231, -0.0154],\n",
      "        [ 0.0315, -0.0262,  0.0059,  ..., -0.0356, -0.0062, -0.0026],\n",
      "        [ 0.0097, -0.0227,  0.0082,  ..., -0.0258, -0.0045,  0.0319],\n",
      "        ...,\n",
      "        [-0.0291,  0.0208,  0.0300,  ...,  0.0109,  0.0239,  0.0282],\n",
      "        [ 0.0011,  0.0347, -0.0112,  ...,  0.0084, -0.0272,  0.0259],\n",
      "        [-0.0299,  0.0239,  0.0134,  ...,  0.0092,  0.0087, -0.0002]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.6905e-02,  3.6230e-02, -1.6542e-02,  2.7734e-02, -6.8030e-03,\n",
      "         2.9756e-02,  6.9669e-03, -5.1863e-03, -5.8233e-03, -5.2764e-03,\n",
      "         2.7640e-02, -2.6019e-02, -2.1792e-02,  3.6611e-03, -1.2398e-03,\n",
      "        -1.4547e-02, -1.2239e-02,  7.4232e-03,  6.0214e-03,  2.8080e-02,\n",
      "        -2.6775e-02, -1.1291e-02,  1.0311e-02,  1.5304e-02,  9.4879e-03,\n",
      "        -1.6575e-02,  1.6566e-02, -3.0821e-02, -1.9482e-02, -1.4785e-03,\n",
      "         5.6605e-03,  1.0055e-02, -3.3401e-02,  2.8362e-02, -9.4393e-03,\n",
      "         7.4286e-03,  2.6345e-02,  4.4949e-02,  2.0903e-02,  4.6418e-03,\n",
      "        -2.5906e-02,  8.3696e-03,  3.7086e-02, -1.2324e-02, -3.0972e-02,\n",
      "         2.9312e-02, -1.0255e-02,  1.5001e-02,  4.3593e-03, -1.5997e-02,\n",
      "        -2.3223e-02,  1.2565e-02, -1.7236e-03,  1.5463e-02,  1.7684e-02,\n",
      "         3.6280e-02,  1.4584e-02,  3.1071e-02,  2.0960e-02, -6.7871e-04,\n",
      "         1.2970e-02,  2.3720e-02,  1.6817e-02,  2.7034e-02,  1.2395e-02,\n",
      "         1.1363e-02, -2.6286e-02, -1.4763e-02,  2.3999e-03,  3.0540e-02,\n",
      "         6.8834e-03,  2.6365e-02,  1.9844e-02,  1.9538e-02, -1.4886e-02,\n",
      "         6.2808e-03,  3.7970e-03, -2.4490e-02, -3.0480e-02,  6.7788e-03,\n",
      "         3.4014e-02,  8.5796e-03, -1.3622e-02, -2.5712e-02, -1.9178e-02,\n",
      "        -2.7473e-02, -7.0269e-03, -2.7870e-02,  9.4127e-03, -1.8779e-02,\n",
      "         3.0087e-02,  1.6219e-02, -3.0407e-02,  3.0118e-03,  4.9500e-03,\n",
      "         2.3426e-03, -1.1818e-02,  1.1221e-02, -4.5780e-03,  2.8271e-02,\n",
      "         1.2621e-02,  2.6248e-02,  1.3844e-02,  3.0480e-02,  2.3867e-02,\n",
      "         3.6749e-02,  3.1550e-02,  1.9081e-03,  9.6973e-03,  1.8576e-02,\n",
      "         1.8427e-02,  3.0979e-02,  1.6157e-02, -1.1736e-02,  6.8108e-03,\n",
      "         2.6355e-02, -1.4868e-02,  1.6800e-03,  3.4551e-02, -5.4603e-03,\n",
      "        -1.2023e-02,  3.6802e-02,  3.4697e-02,  1.3149e-02,  1.7572e-03,\n",
      "         1.3875e-02,  2.4243e-02,  2.2981e-02, -2.4262e-02, -1.9528e-02,\n",
      "        -3.2471e-02,  1.0000e-02, -1.8370e-02,  1.1922e-02, -1.0913e-02,\n",
      "        -3.3150e-02,  2.2040e-02,  2.2380e-02,  4.7006e-03, -2.3140e-02,\n",
      "         3.0448e-02, -3.0862e-02,  1.6944e-02,  2.1033e-02, -1.3006e-02,\n",
      "         3.1570e-02,  3.5684e-02, -4.4630e-03,  1.9239e-02,  2.1002e-02,\n",
      "         1.7982e-02, -1.0673e-02,  9.5004e-03,  2.3908e-02, -2.7292e-02,\n",
      "        -2.1630e-02, -4.9107e-03,  3.0148e-02, -2.9738e-02,  1.4544e-02,\n",
      "        -5.5408e-04, -1.8843e-02, -5.9226e-03, -2.2514e-02, -1.6565e-02,\n",
      "         1.9397e-02, -2.0586e-02, -1.4014e-02, -2.4364e-02, -2.2041e-02,\n",
      "        -2.3167e-03, -5.3216e-03,  7.7172e-03,  3.6545e-02, -3.9687e-03,\n",
      "        -3.0220e-02,  2.0605e-02,  8.8433e-03,  2.5531e-02,  3.9670e-03,\n",
      "        -1.6461e-02, -1.4551e-02, -8.8092e-03,  1.8783e-02, -1.1872e-02,\n",
      "         1.5623e-03, -3.6599e-02,  7.3398e-03, -6.9858e-03, -2.9947e-02,\n",
      "        -2.5608e-02, -1.3924e-02, -9.8683e-03, -3.0488e-02, -1.7369e-02,\n",
      "         1.5201e-02, -3.4950e-03, -1.4127e-02, -1.9661e-02,  3.3843e-02,\n",
      "         9.8236e-03,  3.2609e-02, -1.8615e-02,  9.2461e-03, -8.9503e-03,\n",
      "         2.2956e-02,  8.1890e-03, -3.2829e-02, -2.8822e-02,  1.6644e-02,\n",
      "        -3.6957e-03,  6.6105e-03, -1.4406e-02,  1.8982e-02, -1.8641e-02,\n",
      "         2.5340e-02,  1.1825e-02, -1.3781e-02, -1.2364e-02,  1.3001e-02,\n",
      "        -2.1632e-02, -2.0331e-02, -9.3611e-03,  2.0235e-03,  7.5049e-03,\n",
      "         9.3903e-03,  1.1912e-02, -2.0975e-02,  1.0137e-02,  2.5671e-03,\n",
      "        -1.7921e-02,  9.9205e-03,  9.8867e-03, -6.1405e-03,  1.1536e-02,\n",
      "        -2.0166e-02,  4.4093e-02, -4.7975e-03, -2.2392e-02, -2.8604e-02,\n",
      "        -2.7614e-02, -1.2213e-03,  3.1541e-02, -3.1071e-02, -2.8243e-02,\n",
      "         1.9784e-02, -7.0729e-03,  1.1095e-02,  3.3138e-02, -5.9557e-03,\n",
      "        -1.1607e-02, -9.0552e-03, -2.7028e-02, -2.1388e-02, -2.1803e-03,\n",
      "        -2.2304e-02, -1.3373e-02, -2.1191e-02, -8.1380e-03, -2.1668e-02,\n",
      "        -6.4036e-03, -3.2794e-02,  2.3711e-02, -3.0466e-02,  2.0726e-02,\n",
      "         1.0067e-02,  2.8780e-03, -1.4254e-03, -1.0756e-02, -2.0124e-02,\n",
      "         1.8082e-02,  8.2380e-03,  3.6911e-02,  3.2408e-02,  6.3221e-03,\n",
      "         6.2036e-03,  2.5427e-02,  2.6641e-02,  2.9922e-02,  1.3988e-02,\n",
      "         1.5176e-02, -2.9327e-02,  6.9657e-03, -3.1459e-02, -1.7219e-02,\n",
      "        -2.2734e-02,  2.9490e-02, -6.2395e-03,  2.8097e-02, -6.5038e-03,\n",
      "        -2.2071e-02, -2.4119e-02,  1.4536e-02, -1.8372e-02,  4.4318e-02,\n",
      "        -2.7797e-02, -3.0506e-02,  1.7802e-02, -2.5722e-02,  1.1642e-02,\n",
      "        -2.0267e-03, -3.7176e-02, -4.5592e-04,  1.9203e-02,  9.4466e-03,\n",
      "         6.0709e-03, -8.6550e-03,  1.6634e-02, -4.3525e-03,  2.7206e-02,\n",
      "        -1.6896e-02, -3.3413e-02,  7.0804e-03,  1.9218e-02, -2.5352e-02,\n",
      "         1.9343e-02,  3.2306e-02,  2.1672e-02, -2.8114e-02,  2.1528e-02,\n",
      "        -3.2722e-03, -2.9496e-02, -2.5956e-02, -2.1950e-02,  3.3464e-02,\n",
      "        -1.9168e-03,  3.4184e-03,  3.4657e-02, -2.2984e-02, -2.5693e-02,\n",
      "        -2.0238e-02,  1.5091e-02, -3.4423e-02, -2.8767e-02, -2.7881e-02,\n",
      "         1.8629e-02, -3.1244e-02, -3.5447e-03,  4.8442e-02, -3.1224e-03,\n",
      "         1.0322e-02,  4.2164e-02,  2.9652e-02,  1.6025e-02,  2.7323e-02,\n",
      "        -2.5763e-02, -2.2396e-02,  2.3000e-02, -1.3030e-03, -5.3392e-03,\n",
      "        -2.7549e-02, -7.1160e-04, -7.6499e-03, -1.0620e-02, -1.5660e-02,\n",
      "         1.2605e-02, -2.6664e-02, -2.0350e-02,  3.7107e-02, -2.2424e-02,\n",
      "        -1.4921e-02,  9.5283e-03, -1.8955e-02, -2.9701e-02, -2.5218e-02,\n",
      "         1.7410e-02, -2.1966e-02, -5.3470e-03,  2.0940e-02,  3.2388e-02,\n",
      "        -2.5930e-02,  3.3068e-02,  3.3370e-02, -5.6558e-03, -2.9104e-04,\n",
      "         3.1505e-02, -6.5441e-03,  1.9201e-02, -1.7860e-02, -1.3498e-02,\n",
      "        -4.3292e-03, -5.0219e-03,  2.6206e-02, -3.1988e-02, -1.5713e-02,\n",
      "        -2.8533e-02, -2.3084e-02, -2.0500e-02, -1.5329e-02, -2.0300e-02,\n",
      "        -2.1966e-03,  6.6380e-03, -3.6072e-02, -9.8682e-03,  2.1870e-02,\n",
      "         1.0202e-02,  1.2767e-02,  2.5050e-02,  2.0082e-02,  3.2840e-02,\n",
      "         2.7077e-02,  1.6508e-02, -2.1869e-02,  3.1870e-02, -1.1919e-02,\n",
      "         2.1259e-02, -3.2013e-02,  2.2278e-02,  2.6708e-02,  2.4198e-02,\n",
      "        -1.4107e-03, -1.5832e-02,  1.4958e-02, -1.4838e-02, -1.6342e-02,\n",
      "        -9.8367e-03, -3.0731e-02,  1.4747e-02,  2.2213e-02, -2.6385e-02,\n",
      "         2.2430e-02,  3.4923e-03,  2.8077e-02,  3.2846e-02,  2.1672e-02,\n",
      "        -6.6408e-03, -2.7644e-03,  2.3695e-02, -1.7108e-02, -1.1204e-02,\n",
      "        -1.8173e-02,  2.1068e-02,  2.7352e-02,  2.8854e-02, -1.5694e-02,\n",
      "        -9.2028e-03, -6.9645e-03, -1.8624e-03,  1.2739e-02, -2.7177e-02,\n",
      "         7.5065e-03, -6.3385e-03,  1.5881e-02,  5.5905e-03, -7.6190e-05,\n",
      "         7.2429e-03, -2.7849e-02,  2.6876e-02, -1.9377e-02,  2.7601e-02,\n",
      "         3.9714e-02,  9.3735e-03,  6.5283e-03,  5.0436e-03, -1.4424e-02,\n",
      "        -2.2814e-02,  1.0837e-02,  2.9701e-02,  6.6472e-03,  9.8460e-03,\n",
      "        -3.3080e-02, -1.5447e-03,  1.1010e-02,  6.2826e-03,  2.2775e-02,\n",
      "        -8.3125e-03,  3.6564e-03,  3.7931e-03, -3.5567e-02,  1.8150e-02,\n",
      "         3.7580e-02,  1.7044e-03,  1.8861e-02,  3.2372e-02,  2.9479e-02,\n",
      "        -3.0870e-02,  2.2196e-02, -3.4159e-02,  2.7039e-02,  1.9441e-02,\n",
      "         1.8277e-02,  1.4927e-02,  3.0738e-02, -5.3293e-03, -3.0942e-02,\n",
      "         2.2781e-02,  2.1916e-02, -2.0534e-02,  1.6738e-02,  2.2049e-02,\n",
      "        -1.8941e-03,  1.2959e-02,  1.6309e-02,  1.5087e-02,  3.4451e-02,\n",
      "        -4.9195e-03,  3.0574e-04,  2.0180e-02,  2.8353e-02, -2.4888e-02,\n",
      "        -1.1010e-02,  3.2337e-02, -2.5564e-02,  1.8834e-02,  1.0959e-02,\n",
      "        -6.9302e-03,  2.3270e-02,  2.3670e-02,  3.0312e-02,  1.1354e-02,\n",
      "         3.8883e-02, -2.5698e-02], device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0185,  0.0416, -0.0163,  ...,  0.0394,  0.0227, -0.0001],\n",
      "        [ 0.0347, -0.0421, -0.0170,  ...,  0.0248, -0.0309,  0.0083],\n",
      "        [ 0.0216,  0.0027,  0.0209,  ...,  0.0365, -0.0281,  0.0069],\n",
      "        ...,\n",
      "        [-0.0247,  0.0307,  0.0233,  ..., -0.0020, -0.0195,  0.0431],\n",
      "        [-0.0229,  0.0414,  0.0315,  ...,  0.0085, -0.0001,  0.0163],\n",
      "        [ 0.0162,  0.0301, -0.0058,  ..., -0.0233,  0.0176, -0.0021]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.1868e-02,  3.9471e-02,  1.4320e-02, -1.5544e-02,  4.5934e-02,\n",
      "        -5.7664e-03, -3.9638e-02,  4.8862e-02, -2.8492e-03,  5.0905e-02,\n",
      "         2.0171e-03, -4.8686e-02,  1.3788e-02, -2.4684e-02, -4.1222e-02,\n",
      "         3.4958e-02, -5.2872e-03,  5.3940e-03,  1.5106e-02, -1.0607e-02,\n",
      "         1.3135e-02,  3.1015e-02, -3.5853e-02,  6.3779e-03, -4.0709e-02,\n",
      "        -2.9012e-02,  1.5663e-02, -6.8919e-03,  5.0558e-02,  4.0863e-02,\n",
      "         2.0654e-02,  2.0981e-02, -1.4957e-02,  1.0386e-02, -8.8759e-03,\n",
      "        -3.7835e-02, -1.5473e-03,  4.8058e-02, -1.8977e-02,  3.9844e-02,\n",
      "         9.5646e-03,  1.6402e-02, -3.5637e-02, -3.4192e-02, -4.4213e-02,\n",
      "         3.0409e-02, -4.7198e-03,  4.1420e-02, -2.7853e-02, -1.3540e-02,\n",
      "         2.7638e-02,  3.8221e-02, -3.9897e-03, -3.3405e-02, -1.4532e-02,\n",
      "        -3.1899e-02, -4.9800e-02, -1.9009e-02, -4.2648e-02,  1.4492e-02,\n",
      "         4.9222e-02,  5.5542e-03,  3.1687e-02,  3.9491e-02,  5.7258e-02,\n",
      "        -2.0585e-03,  1.3564e-02,  2.7731e-02,  2.3654e-02,  5.0969e-03,\n",
      "         3.3949e-02,  4.3012e-02,  5.3629e-02,  6.7145e-02,  3.0931e-02,\n",
      "         1.5197e-02, -9.1943e-03,  2.8491e-02,  2.5543e-02, -4.3029e-02,\n",
      "        -7.2926e-03, -3.8105e-02,  7.3636e-03, -2.0345e-02,  1.3771e-02,\n",
      "        -1.5329e-02, -2.4084e-02,  3.3134e-02, -3.8063e-02, -2.1222e-02,\n",
      "        -2.8730e-02,  4.0359e-02, -1.1688e-02, -8.5268e-04, -1.7783e-02,\n",
      "         3.1523e-02, -2.8407e-02,  4.6230e-02,  2.5913e-02,  2.0775e-02,\n",
      "         6.3212e-03, -1.6424e-02, -8.9719e-03,  3.8032e-02,  3.6789e-02,\n",
      "        -2.2455e-02,  4.2923e-02, -3.9080e-02,  4.2156e-02, -2.3964e-02,\n",
      "         4.7232e-02,  1.5407e-02, -3.2195e-02, -1.0757e-03, -3.7933e-03,\n",
      "        -1.6761e-03, -3.0088e-02,  4.6087e-02, -1.3590e-04,  3.7971e-02,\n",
      "        -2.0087e-02,  4.5423e-04, -9.6215e-04,  9.6854e-05,  3.1583e-02,\n",
      "         3.9627e-03, -3.3323e-02,  2.7380e-02, -3.1072e-02, -1.9396e-03,\n",
      "         3.3096e-02, -1.6925e-02,  4.6072e-04, -2.7074e-02,  2.7499e-02,\n",
      "         2.2659e-02,  5.6745e-03,  1.2782e-02, -4.7572e-03,  2.5481e-02,\n",
      "        -2.7607e-02,  9.7092e-03, -2.6232e-02, -2.3522e-02, -2.0384e-02,\n",
      "         3.6619e-02,  3.1590e-02,  3.2036e-02,  3.7671e-02,  9.9668e-03,\n",
      "        -1.0237e-02,  2.3071e-02,  1.0309e-02, -1.3767e-02, -4.9995e-03,\n",
      "         3.5276e-02,  4.1772e-02, -1.1619e-03, -2.8986e-02,  2.8784e-02,\n",
      "         2.4028e-02,  1.1809e-02,  2.8953e-02, -2.1807e-02, -4.3089e-02,\n",
      "         2.7066e-02,  2.3085e-02,  3.9336e-02,  3.2690e-02,  3.0567e-02,\n",
      "         3.6301e-02, -3.1929e-02, -1.8576e-02, -3.7008e-03, -1.4930e-02,\n",
      "        -2.7544e-02, -4.3831e-02,  4.8362e-02, -4.3661e-02, -2.8902e-03,\n",
      "         4.5835e-02, -1.5674e-02,  4.4492e-02,  1.6727e-02, -1.6480e-02,\n",
      "        -1.2228e-02, -3.1752e-02,  6.5128e-05,  1.1791e-02,  1.7203e-02,\n",
      "         2.3310e-02, -2.4314e-02, -3.9848e-02, -1.4550e-02,  3.1640e-02,\n",
      "        -1.0045e-02,  3.4060e-02,  3.3865e-02, -1.9829e-02,  3.3147e-03,\n",
      "        -2.1123e-02,  2.9096e-02, -3.8314e-02,  2.4258e-02,  1.5643e-02,\n",
      "         4.3963e-03, -2.2307e-02, -3.7684e-02,  4.1696e-02, -3.8696e-02,\n",
      "        -1.5509e-02, -4.0977e-02,  2.4328e-02,  2.2995e-02, -3.8131e-02,\n",
      "         2.3391e-02,  4.6125e-02,  2.3403e-02,  4.3857e-02,  2.7806e-02,\n",
      "         7.4949e-03,  3.4622e-02,  1.3260e-02,  3.0888e-02,  4.1009e-02,\n",
      "        -1.6169e-02,  7.6058e-03, -3.8084e-02, -1.0166e-02,  1.5415e-02,\n",
      "         3.3055e-02, -3.4873e-02, -6.7153e-03, -8.8727e-04,  2.3850e-05,\n",
      "        -1.1735e-02, -5.3545e-03,  1.6650e-02,  9.6742e-03, -1.9114e-02,\n",
      "         3.5193e-02, -8.7322e-03, -6.2351e-03, -2.3175e-03, -1.2762e-02,\n",
      "         2.9412e-03,  5.3921e-02, -2.3306e-02,  9.9379e-03, -2.0168e-02,\n",
      "        -1.5323e-02,  3.1521e-02,  6.2951e-03, -2.3931e-02, -2.6807e-02,\n",
      "         4.5375e-02, -8.7335e-03,  1.7005e-02,  5.5761e-03, -1.8076e-03,\n",
      "         2.3736e-02,  9.2089e-03,  5.0866e-02, -1.8193e-03,  1.1158e-02,\n",
      "        -1.6380e-02, -2.8268e-02,  1.7776e-02,  3.2448e-02,  1.4402e-02,\n",
      "         8.4558e-03, -2.7512e-02, -1.1666e-02, -8.8761e-03,  2.3586e-02,\n",
      "         5.9437e-03,  2.5778e-02,  6.3798e-03, -4.5457e-02, -1.9844e-03,\n",
      "         2.5286e-02, -2.2780e-02,  7.7982e-03, -2.3100e-02,  3.9115e-02,\n",
      "         4.1181e-02,  2.6571e-02, -1.1890e-02,  3.7913e-02,  4.2195e-02,\n",
      "        -2.5848e-02, -4.0589e-02,  2.1272e-03,  5.5053e-03, -6.9628e-03,\n",
      "         2.9996e-02, -1.8660e-02, -1.1022e-02,  9.0854e-03,  2.4594e-02,\n",
      "         1.3694e-03,  2.2450e-02,  3.9382e-02,  1.8765e-02, -3.2091e-02,\n",
      "         4.1741e-02, -2.6098e-02,  2.2989e-02,  2.1887e-02, -2.7474e-02,\n",
      "        -3.3653e-02, -5.5261e-03, -2.2457e-02,  3.0578e-02,  3.3184e-02,\n",
      "        -3.2154e-03,  1.7796e-02, -4.2781e-02,  5.0812e-02,  2.1017e-02,\n",
      "        -6.0930e-03,  3.0787e-02,  3.5229e-02,  4.0427e-02, -4.5262e-03,\n",
      "        -9.5177e-03, -3.6260e-02, -2.4639e-02, -8.8782e-03, -4.3050e-02,\n",
      "        -3.1407e-02,  4.5904e-02,  1.1387e-02,  8.5525e-03,  3.0121e-02,\n",
      "         1.2244e-02,  4.8186e-02, -1.1116e-02, -3.3124e-02, -9.3806e-03,\n",
      "        -2.5781e-02, -2.9599e-02,  3.0066e-02,  6.2726e-03,  1.7932e-02,\n",
      "        -4.1525e-02, -3.4847e-02,  3.3178e-02, -4.3329e-02, -3.1399e-03,\n",
      "        -3.5580e-02, -3.7529e-02, -2.4135e-02, -4.0973e-02,  3.3747e-02,\n",
      "         2.4373e-02, -9.1850e-03,  8.9546e-03,  1.8883e-02,  3.4545e-02,\n",
      "        -2.4092e-02,  3.1982e-02,  2.8697e-02,  3.8250e-02, -1.4207e-03,\n",
      "         4.3828e-02,  3.3473e-02,  6.8849e-03, -3.3105e-03,  2.4125e-02,\n",
      "        -4.3889e-02, -9.8408e-03, -1.4458e-02,  2.5197e-02, -3.2226e-03,\n",
      "         3.4528e-02, -1.2739e-02, -2.2978e-02, -3.6060e-02,  4.0503e-02,\n",
      "        -1.3712e-02,  2.9428e-02,  2.7945e-02,  1.3097e-04, -1.5135e-02,\n",
      "         4.2422e-02,  4.7618e-03, -3.7890e-03, -4.1461e-02,  3.9396e-02,\n",
      "        -4.1682e-02,  1.4952e-02,  3.1487e-02, -3.1212e-02, -1.9719e-02,\n",
      "         2.0976e-02, -2.1538e-02, -2.7592e-02,  7.6613e-03, -1.0350e-02,\n",
      "        -1.9918e-02, -2.5747e-02,  7.1906e-03, -1.2347e-02,  3.4926e-02,\n",
      "        -1.7320e-02, -4.1782e-02, -3.2434e-02, -2.4841e-02, -3.0932e-03,\n",
      "         1.4742e-02,  7.3002e-03,  3.1897e-02, -3.5364e-02, -3.2646e-03,\n",
      "         4.3544e-03,  2.6156e-02, -2.2035e-02,  1.6968e-02,  1.1849e-02,\n",
      "        -2.4773e-02, -1.6489e-02,  7.2621e-03,  1.2418e-02, -1.5766e-02,\n",
      "         4.9466e-02, -2.1893e-02, -3.7684e-02, -4.9966e-02,  4.8459e-02,\n",
      "         3.4598e-02,  1.9517e-03, -1.2595e-02, -2.7068e-02, -2.2227e-02,\n",
      "         3.6419e-02,  3.3908e-02,  1.5689e-02, -3.4459e-02,  3.6090e-02,\n",
      "        -2.5667e-02,  1.4371e-02,  2.5637e-02, -4.5448e-02, -2.6484e-02,\n",
      "         2.5834e-02,  5.9443e-03, -1.1336e-02, -3.0976e-02,  5.9122e-03,\n",
      "        -3.6542e-03, -1.3673e-02, -2.2891e-02, -2.2944e-02, -2.1385e-02,\n",
      "        -2.5530e-02,  3.7301e-02, -4.1884e-02, -8.0922e-03, -1.4268e-03,\n",
      "        -2.3754e-02, -3.1898e-02,  3.3313e-02,  2.5582e-02, -1.7101e-02,\n",
      "        -2.1009e-02,  4.0139e-02,  4.1670e-02,  1.1904e-02, -2.8049e-02,\n",
      "        -3.8167e-02, -3.1326e-02,  3.7707e-02,  4.0373e-02,  3.3511e-02,\n",
      "         7.1915e-04, -2.1215e-03, -1.8679e-02,  2.6969e-02, -1.2551e-02,\n",
      "        -2.7642e-02,  1.8978e-03, -3.9047e-02, -2.1394e-02,  1.6928e-02,\n",
      "        -8.4200e-04, -3.6264e-02,  3.6005e-02, -1.0203e-02,  1.5594e-02,\n",
      "         3.5204e-02,  2.0309e-04, -3.0854e-02, -1.2514e-02, -6.6860e-03,\n",
      "         2.8638e-03,  2.1707e-02, -4.0739e-03, -3.6366e-02, -1.7600e-02,\n",
      "        -3.0914e-02, -7.6680e-03,  2.5069e-02,  3.4304e-03,  8.6267e-03,\n",
      "         2.8433e-02,  1.3328e-02,  5.1692e-02,  3.4996e-02,  1.8545e-03,\n",
      "         7.4396e-03, -9.2766e-03], device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0061, -0.0484,  0.0479,  ..., -0.0213, -0.0553, -0.0421],\n",
      "        [-0.0296,  0.0642,  0.0790,  ...,  0.0275,  0.0170, -0.0004],\n",
      "        [ 0.0402, -0.0153,  0.0327,  ...,  0.0341, -0.0397,  0.0380],\n",
      "        ...,\n",
      "        [ 0.0277,  0.0534, -0.0906,  ..., -0.0168,  0.0149,  0.0105],\n",
      "        [-0.0140,  0.0355,  0.0018,  ...,  0.0469,  0.0584, -0.0122],\n",
      "        [ 0.0198, -0.0721, -0.0483,  ..., -0.0140,  0.0285,  0.0391]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0606,  0.0468, -0.0436,  0.0239, -0.0792,  0.1493, -0.0380,  0.0231,\n",
      "        -0.0595, -0.0139], device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in p:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98519b88-9ecb-47c4-9236-dbebd202f2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ddeb6ae-0044-478e-8a14-d74ece31c781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "796cc2eb-f148-489a-b760-99f57eac4c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b1f64d8-23af-4680-87a4-2a09a2eb5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(training_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "294cd833-c19f-4c5d-9dbc-dc2316900f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dba7be23-af53-4812-b0ed-a6165a168e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X),type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcad402a-e92c-48ad-bbf1-c393b34bdc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd8c1fb8-4805-4a9f-9920-26eb2eab0c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred),type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13d97c9c-d3ae-45ee-9c0e-9ffef988c6bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss\u001b[38;5;241m=\u001b[39m(pred\u001b[38;5;241m-\u001b[39my)\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "loss=(pred-y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20fef762-4055-4605-a607-bf50fd88b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48b7eb47-04a7-42fd-ab3c-4b918e3e4120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61562824-6a53-48e3-a4b4-70d4877360ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "998e75e2-0ed4-438b-8cde-4daab401a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb1333aa-1a36-4d3b-9b76-b2248ff9defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot=torch.nn.functional.one_hot(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b9b79b8-cec7-4a6b-b950-6f544570e8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([64, 10]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_onehot),y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0421d910-d1b2-45bd-84e1-01bad8ea48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_onehot=(pred-y_onehot).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a2e6cda-b6e2-4ee3-8986-c83391f4c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89566932-e6e4-4ff0-9b22-9156b47debd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.1525317, dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad255b60-d92c-4520-ac09-43dd0ed003aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-54.646942, dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_onehot.detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93106473-8e23-47c7-a4c5-4464776a4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bc967ef-09d4-458b-ad5b-24fdb75945da",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_onehot\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss_onehot.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfe6dff5-b21a-4465-9c04-2cdc32f6e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oneval=pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70114e29-f894-406b-9884-5cb8d34628b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_param_1=list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28052803-40c3-44a0-8276-575dda75b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  7.2642e-07,  ...,  7.0276e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.4769e-07,  ..., -3.5775e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.4980e-06,  ...,  6.7522e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -1.4090e-06,  ..., -6.9300e-05,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -1.7388e-06,  ..., -1.2789e-05,\n",
       "          0.0000e+00,  0.0000e+00]], device='mps:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_param_1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9c090e1-74b7-426c-965c-a4ee62befdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0179,  0.0346,  0.0131,  ...,  0.0124, -0.0231, -0.0154],\n",
       "        [ 0.0315, -0.0262,  0.0059,  ..., -0.0356, -0.0062, -0.0026],\n",
       "        [ 0.0097, -0.0227,  0.0082,  ..., -0.0258, -0.0045,  0.0319],\n",
       "        ...,\n",
       "        [-0.0291,  0.0208,  0.0300,  ...,  0.0109,  0.0239,  0.0282],\n",
       "        [ 0.0011,  0.0347, -0.0112,  ...,  0.0084, -0.0272,  0.0259],\n",
       "        [-0.0299,  0.0239,  0.0134,  ...,  0.0092,  0.0087, -0.0002]],\n",
       "       device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_param_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77a3cc22-ec00-4e31-a29a-a8278ade89d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 784])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_param_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8539a6aa-37e3-4a05-a5f1-40137d11d72f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_oneval\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "pred_oneval.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "770509bc-c5da-4788-88d4-5c6b30404f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_oneval\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "pred_oneval.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32948ec4-e4bc-4573-8018-69a33cce1fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/sw0j9jdj3z7_8nx2zjs29z_5yg7h25/T/ipykernel_83090/217868730.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(torch.rand(5))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2309, 0.1988, 0.2506, 0.1604, 0.1593])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9acbf05-9835-4546-bdd4-44a6a7ff7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.from_numpy(np.array([[3.0,2.9,-3.8,5.6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa77ccd5-82a2-4237-b91c-07a336a046f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/sw0j9jdj3z7_8nx2zjs29z_5yg7h25/T/ipykernel_83090/686876215.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(t).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(t).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ecd929d1-1cca-40c7-a57f-6b10fc06fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fc0d84d-2729-4ee5-b8f6-054d461bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e88c893c-9d63-4422-9dd0-38b6bda501e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "smallq=Q.sum()\n",
    "# backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5e4b9bd-ec33-4b29-81c5-ed8bdc32cfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 4.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34c2b318-e826-4f4d-8ea4-1b4620b8f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallq.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "92af36bb-ae0f-4d62-884c-78db0fc0206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([36., 81.]), tensor([-12.,  -8.]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad,b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41f9607d-84a3-432c-a79a-87aa43d0de0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.]), tensor([0., 0.]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad.zero_(),b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12476543-b7bc-4912-990b-720cf5177080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
